import os
import gzip
import re
import time
import logging
from typing import List, Dict, Set, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests
from lxml import etree
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ===================== é…ç½®åŒº =====================
CONFIG_FILE = "config.txt"
OUTPUT_DIR = "output"
LOG_FILE = "epg_merge.log"
MAX_WORKERS = 3  # å¹¶å‘çº¿ç¨‹æ•°ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
TIMEOUT = 30
CORE_RETRY_COUNT = 2

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# æ ¸å¿ƒé¢‘é“é…ç½®ï¼ˆå±±ä¸œæœ¬åœ°â†’å¤®è§†â†’å…¶ä»–å«è§†ä¼˜å…ˆçº§ï¼‰
CHANNEL_PRIORITY = [
    ("å±±ä¸œæœ¬åœ°", ["å±±ä¸œ"]),
    ("å¤®è§†", ["CCTV"]),
    ("å…¶ä»–å«è§†", ["å«è§†", "æµ™æ±Ÿ", "æ¹–å—", "æ±Ÿè‹", "ä¸œæ–¹", "åŒ—äº¬", "å®‰å¾½", "å¹¿ä¸œ", "æ²³å—", "æ·±åœ³"])
]

# é…·9ä¸“ç”¨IDæ˜ å°„è¡¨ï¼ˆæ•°å­—IDâ†’åç§°IDï¼Œå«å®Œæ•´4Ké¢‘é“ï¼‰
COOL9_ID_MAPPING = {
    # å±±ä¸œæœ¬åœ°é¢‘é“
    "89": "å±±ä¸œå«è§†", "221": "å±±ä¸œæ•™è‚²", "381": "å±±ä¸œæ–°é—»", 
    "382": "å±±ä¸œå†œç§‘", "383": "å±±ä¸œé½é²", "384": "å±±ä¸œæ–‡æ—…",
    # å¤®è§†å¸¸è§„é¢‘é“
    "1": "CCTV1", "2": "CCTV2", "3": "CCTV3", "4": "CCTV4", 
    "5": "CCTV5", "6": "CCTV6", "7": "CCTV7", "8": "CCTV8",
    "9": "CCTV9", "10": "CCTV10",
    # 4Kè¶…é«˜æ¸…é¢‘é“ï¼ˆå®Œæ•´è¡¥å……ï¼‰
    "101": "CCTV4K", "102": "æµ™æ±Ÿå«è§†4K", "103": "æ¹–å—å«è§†4K",
    "104": "ä¸œæ–¹å«è§†4K", "105": "åŒ—äº¬å«è§†4K", "106": "å¹¿ä¸œå«è§†4K",
    "107": "æ·±åœ³å«è§†4K", "108": "å±±ä¸œå«è§†4K"
}

# ===================== é¢‘é“è¿‡æ»¤é…ç½® =====================
# å›½å†…é¢‘é“å…³é”®è¯ï¼ˆå®Œæ•´è¦†ç›–ï¼ŒåŒ…å«æ¸¯æ¾³å°ï¼‰
DOMESTIC_KEYWORDS = [
    # ä¸­å¤®é¢‘é“
    "CCTV", "å¤®è§†", "ä¸­å›½", "ä¸­å¤®",
    
    # çœçº§å«è§†
    "å«è§†", "å±±ä¸œ", "æµ™æ±Ÿ", "æ¹–å—", "æ±Ÿè‹", "ä¸œæ–¹", "åŒ—äº¬", "å®‰å¾½", "å¹¿ä¸œ", 
    "æ²³å—", "æ·±åœ³", "å››å·", "é‡åº†", "å¤©æ´¥", "æ¹–åŒ—", "æ±Ÿè¥¿", "æ²³åŒ—", "å±±è¥¿", 
    "é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å®å¤", "æ–°ç–†", "å†…è’™å¤", "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ",
    "ä¸Šæµ·", "ç¦å»º", "å¹¿è¥¿", "æµ·å—", "è´µå·", "äº‘å—", "è¥¿è—", 
    
    # æ¸¯æ¾³å°åœ°åŒº
    "é¦™æ¸¯", "æ¾³é—¨", "å°æ¹¾", "ç¿¡ç¿ ", "å‡¤å‡°", "äºšè§†", "æ˜ç ", "æœ¬æ¸¯", "å›½é™…",
    "ä¸­å¤©", "ä¸œæ£®", "TVBS", "ä¸‰ç«‹", "æ°‘è§†", "åè§†", "å°è§†", "å…¬è§†",
    
    # åœ°æ–¹é¢‘é“å¸¸è§å…³é”®è¯
    "æ–°é—»", "ç»¼åˆ", "éƒ½å¸‚", "ç”Ÿæ´»", "å½±è§†", "ä½“è‚²", "å°‘å„¿", "æ•™è‚²", "å…¬å…±",
    "ç»æµ", "æ³•åˆ¶", "å†œä¸š", "æ–‡æ—…", "äº¤é€š", "è´­ç‰©", "æˆå‰§", "éŸ³ä¹",
    
    # æ•°å­—é¢‘é“
    "é«˜æ¸…", "4K", "HD", "æ ‡æ¸…", "SD"
]

# å›½å¤–é¢‘é“å…³é”®è¯ï¼ˆæ˜ç¡®å±è”½ï¼‰
FOREIGN_KEYWORDS = [
    # æ¬§ç¾å›½å®¶
    "BBC", "CNN", "FOX", "HBO", "Discovery", "National Geographic", "ESPN",
    "MTV", "VH1", "Disney", "Cartoon Network", "Nickelodeon",
    "ABC", "NBC", "CBS", "PBS", "Sky", "ITV", "France", "Deutsche",
    "RTL", "TF1", "RAI", "NHK", "KBS", "MBC", "SBS", "Arirang",
    
    # å…¶ä»–å¤–è¯­å…³é”®è¯
    "English", "Sports", "Movie", "News", "Entertainment", "Music",
    "Kids", "Family", "Documentary", "Lifestyle", "Travel", "Food",
    "Fashion", "Business", "Finance", "Religion", "God", "Church",
    
    # å›½å®¶/åœ°åŒºåç§°
    "USA", "UK", "Britain", "British", "American", "Canada", "Canadian",
    "Australia", "Australian", "New Zealand", "Germany", "German",
    "France", "French", "Italy", "Italian", "Spain", "Spanish",
    "Japan", "Japanese", "Korea", "Korean", "Russia", "Russian",
    "India", "Indian", "Thailand", "Thai", "Vietnam", "Vietnamese",
    
    # å«æ˜Ÿç”µè§†æ ‡è¯†
    "Satellite", "Sat", "DTH", "DBS", "Asia", "Pacific", "World",
    "International", "Global", "Euro", "European"
]

# ç‰¹æ®Šå¤„ç†é¢‘é“ï¼ˆå¼ºåˆ¶ä¿ç•™çš„ç‰¹å®šé¢‘é“ï¼Œå³ä½¿åŒ…å«å›½å¤–å…³é”®è¯ï¼‰
WHITELIST_CHANNELS = [
    "CCTV-4", "CCTV-9", "CCTV News",  # å¤®è§†å›½é™…é¢‘é“
    "å‡¤å‡°å«è§†", "å‡¤å‡°ä¸­æ–‡", "å‡¤å‡°èµ„è®¯", "å‡¤å‡°é¦™æ¸¯",  # å‡¤å‡°å«è§†ç³»åˆ—
    "ç¿¡ç¿ å°", "æ˜ç å°", "æœ¬æ¸¯å°", "å›½é™…å°",  # é¦™æ¸¯æœ¬åœ°é¢‘é“
]

# ==================================================

class EPGGenerator:
    def __init__(self):
        self.session = self._create_session()
        self.channel_ids: Set[str] = set()
        self.priority_channels = {cat[0]: [] for cat in CHANNEL_PRIORITY}
        self.other_channels: List = []
        self.all_programs: List = []
        self.filtered_foreign_count = 0
        
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯"""
        session = requests.Session()
        retry_strategy = Retry(
            total=CORE_RETRY_COUNT + 2,
            backoff_factor=1.5,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/xml, */*",
            "Accept-Encoding": "gzip, deflate"
        })
        return session

    def read_epg_sources(self) -> List[str]:
        """è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„EPGæº"""
        if not os.path.exists(CONFIG_FILE):
            logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
            
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                sources = []
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line and not line.startswith("#"):
                        if line.startswith(("http://", "https://")):
                            sources.append(line)
                        else:
                            logging.warning(f"ç¬¬{line_num}è¡Œæ ¼å¼é”™è¯¯ï¼Œå·²è·³è¿‡: {line}")
                
                if len(sources) < 3:
                    logging.warning(f"ä»…æ‰¾åˆ°{len(sources)}ä¸ªæœ‰æ•ˆEPGæºï¼Œå»ºè®®è‡³å°‘é…ç½®3ä¸ª")
                
                return sources[:8]  # é™åˆ¶æœ€å¤§æºæ•°é‡ï¼Œé¿å…è¿‡åº¦æŠ“å–
                
        except Exception as e:
            logging.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    def clean_xml_content(self, content: str) -> str:
        """æ¸…ç†XMLå†…å®¹ä¸­çš„æ— æ•ˆå­—ç¬¦ï¼Œé¿å…è§£ææŠ¥é”™"""
        # ç§»é™¤æ§åˆ¶å­—ç¬¦å’ŒéXMLæ ‡å‡†å­—ç¬¦
        content_clean = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', content)
        # ä¿®å¤å¸¸è§çš„XMLè½¬ä¹‰é—®é¢˜
        content_clean = content_clean.replace('& ', '&amp; ')
        return content_clean

    def fetch_single_source(self, source: str) -> Tuple[bool, str, any]:
        """å¹¶å‘è·å–å•ä¸ªEPGæºæ•°æ®"""
        try:
            start_time = time.time()
            logging.info(f"å¼€å§‹æŠ“å–: {source}")
            
            response = self.session.get(source, timeout=TIMEOUT)
            response.raise_for_status()
            
            # å¤„ç†gzipå‹ç¼©
            if source.endswith('.gz'):
                content = gzip.decompress(response.content).decode('utf-8')
            else:
                content = response.text
                
            # æ¸…ç†XMLå†…å®¹ï¼Œé¿å…è§£æå¤±è´¥
            content_clean = self.clean_xml_content(content)
            xml_tree = etree.fromstring(content_clean.encode('utf-8'))
            
            cost_time = time.time() - start_time
            logging.info(f"æˆåŠŸæŠ“å–: {source} | è€—æ—¶: {cost_time:.2f}s")
            return True, source, xml_tree
            
        except Exception as e:
            logging.error(f"æŠ“å–å¤±è´¥ {source}: {str(e)}")
            return False, source, None

    def should_keep_channel(self, channel_name: str) -> Tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿ç•™è¯¥é¢‘é“ï¼Œè¿”å›(æ˜¯å¦ä¿ç•™, åŸå› )"""
        channel_name_lower = channel_name.lower()
        
        # 1. é¦–å…ˆæ£€æŸ¥ç™½åå•ï¼ˆå¼ºåˆ¶ä¿ç•™ï¼‰
        for white_channel in WHITELIST_CHANNELS:
            if white_channel in channel_name:
                return True, f"ç™½åå•é¢‘é“: {white_channel}"
        
        # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«å›½å†…å…³é”®è¯
        has_domestic_keyword = any(kw in channel_name for kw in DOMESTIC_KEYWORDS)
        
        # 3. æ£€æŸ¥æ˜¯å¦åŒ…å«å›½å¤–å…³é”®è¯
        has_foreign_keyword = any(
            fk.lower() in channel_name_lower for fk in FOREIGN_KEYWORDS
        )
        
        # 4. åˆ¤æ–­é€»è¾‘ï¼š
        #    - å¦‚æœåŒ…å«å›½å†…å…³é”®è¯ï¼Œä¿ç•™
        #    - å¦‚æœä¸å«å›½å†…å…³é”®è¯ä½†å«å›½å¤–å…³é”®è¯ï¼Œè¿‡æ»¤
        #    - å¦‚æœéƒ½ä¸å«ï¼Œå¯èƒ½æ˜¯åœ°æ–¹é¢‘é“ï¼Œæ ¹æ®å…¶ä»–è§„åˆ™åˆ¤æ–­
        
        if has_domestic_keyword:
            if has_foreign_keyword:
                # åŒæ—¶åŒ…å«å›½å†…å¤–å…³é”®è¯ï¼Œä»¥å›½å†…ä¸ºä¸»ï¼ˆå¯èƒ½æ˜¯"BBCä¸­æ–‡"ä¹‹ç±»çš„ï¼‰
                domestic_kws = [kw for kw in DOMESTIC_KEYWORDS if kw in channel_name]
                return True, f"åŒ…å«å›½å†…å…³é”®è¯: {domestic_kws}"
            else:
                # åªå«å›½å†…å…³é”®è¯ï¼Œè‚¯å®šä¿ç•™
                domestic_kws = [kw for kw in DOMESTIC_KEYWORDS if kw in channel_name]
                return True, f"åŒ…å«å›½å†…å…³é”®è¯: {domestic_kws}"
        else:
            if has_foreign_keyword:
                # åªå«å›½å¤–å…³é”®è¯ï¼Œè¿‡æ»¤
                foreign_kws = [fk for fk in FOREIGN_KEYWORDS if fk.lower() in channel_name_lower]
                return False, f"åŒ…å«å›½å¤–å…³é”®è¯: {foreign_kws}"
            else:
                # éƒ½ä¸åŒ…å«ï¼Œå¯èƒ½æ˜¯æ•°å­—é¢‘é“æˆ–åœ°æ–¹å°ï¼Œæ ¹æ®é¢å¤–è§„åˆ™åˆ¤æ–­
                # è§„åˆ™ï¼šä¸­æ–‡é¢‘é“ä¿ç•™ï¼Œçº¯è‹±æ–‡/æ•°å­—é¢‘é“è¿‡æ»¤
                chinese_chars = sum(1 for c in channel_name if '\u4e00' <= c <= '\u9fff')
                if chinese_chars >= 2:  # è‡³å°‘2ä¸ªä¸­æ–‡å­—ç¬¦
                    return True, "ä¸­æ–‡é¢‘é“"
                else:
                    return False, "éä¸­æ–‡é¢‘é“"

    def process_channels(self, xml_tree, source: str) -> Tuple[int, int]:
        """å¤„ç†é¢‘é“æ•°æ®ï¼Œå«åˆ†ç±»ã€è¿‡æ»¤ã€ç»Ÿè®¡"""
        channels = xml_tree.xpath("//channel")
        shandong_count = 0
        filtered_count = 0
        
        for channel in channels:
            cid = channel.get("id", "").strip()
            if not cid:
                continue
                
            # åº”ç”¨é…·9IDæ˜ å°„ï¼ˆæ•°å­—IDâ†’åç§°IDï¼‰
            if cid in COOL9_ID_MAPPING:
                cid = COOL9_ID_MAPPING[cid]
                
            if cid in self.channel_ids:
                continue  # è·³è¿‡é‡å¤é¢‘é“
                
            # è·å–é¢‘é“åç§°
            display_names = channel.xpath(".//display-name/text()")
            channel_name = display_names[0].strip() if display_names else ""
            
            if not channel_name:
                continue  # è·³è¿‡æ— åé¢‘é“
                
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿ç•™è¯¥é¢‘é“
            keep_channel, reason = self.should_keep_channel(channel_name)
            
            if not keep_channel:
                filtered_count += 1
                self.filtered_foreign_count += 1
                logging.debug(f"è¿‡æ»¤å›½å¤–é¢‘é“: {channel_name} | åŸå› : {reason}")
                continue
                
            # æ›´æ–°é¢‘é“IDï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰
            channel.set("id", cid)
            self.channel_ids.add(cid)
            
            # æŒ‰ä¼˜å…ˆçº§åˆ†ç±»
            channel_added = False
            for cat_name, keywords in CHANNEL_PRIORITY:
                if any(kw in channel_name for kw in keywords):
                    self.priority_channels[cat_name].append(channel)
                    channel_added = True
                    if "å±±ä¸œ" in channel_name:
                        shandong_count += 1  # ç»Ÿè®¡å±±ä¸œæœ¬åœ°é¢‘é“
                    break
                    
            if not channel_added:
                self.other_channels.append(channel)
                
        return shandong_count, filtered_count

    def process_programs(self, xml_tree):
        """å¤„ç†èŠ‚ç›®å•æ•°æ®ï¼Œæ˜ å°„é…·9é¢‘é“IDï¼ŒåŒæ—¶è¿‡æ»¤å›½å¤–é¢‘é“èŠ‚ç›®"""
        programs = xml_tree.xpath("//programme")
        for program in programs:
            channel_id = program.get("channel", "")
            
            # é¦–å…ˆæ£€æŸ¥é¢‘é“IDæ˜¯å¦åœ¨ä¿ç•™åˆ—è¡¨ä¸­
            if channel_id in self.channel_ids or channel_id in COOL9_ID_MAPPING.values():
                # èŠ‚ç›®å•é¢‘é“IDæ˜ å°„ï¼ˆä¸é¢‘é“IDä¿æŒä¸€è‡´ï¼‰
                if channel_id in COOL9_ID_MAPPING:
                    program.set("channel", COOL9_ID_MAPPING[channel_id])
                self.all_programs.append(program)

    def fetch_all_sources(self, sources: List[str]) -> bool:
        """å¹¶å‘è·å–æ‰€æœ‰EPGæºæ•°æ®å¹¶å¤„ç†"""
        successful_sources = 0
        
        with ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(sources))) as executor:
            future_to_source = {
                executor.submit(self.fetch_single_source, source): source 
                for source in sources
            }
            
            for future in as_completed(future_to_source):
                source = future_to_source[future]
                try:
                    success, _, xml_tree = future.result()
                    if success and xml_tree is not None:
                        shandong_count, filtered_count = self.process_channels(xml_tree, source)
                        self.process_programs(xml_tree)
                        successful_sources += 1
                        logging.info(f"å¤„ç†å®Œæˆ: {source} | å±±ä¸œé¢‘é“: {shandong_count}ä¸ª | è¿‡æ»¤å›½å¤–: {filtered_count}ä¸ª")
                        
                except Exception as e:
                    logging.error(f"å¤„ç†æºæ•°æ®å¤±è´¥ {source}: {str(e)}")
        
        return successful_sources > 0

    def generate_final_xml(self) -> str:
        """ç”Ÿæˆæœ€ç»ˆçš„EPG XMLæ–‡ä»¶ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰"""
        # åˆ›å»ºXMLæ ¹èŠ‚ç‚¹
        xml_declare = f'''<?xml version="1.0" encoding="UTF-8"?>
<tv generator-info-name="optimized-epg-generator" 
    generator-info-url="https://github.com/fxq12345/epg" 
    last-update="{time.strftime("%Y%m%d%H%M%S")}">'''
        
        root = etree.fromstring(f"{xml_declare}</tv>".encode("utf-8"))
        
        # æŒ‰ä¼˜å…ˆçº§æ·»åŠ é¢‘é“ï¼ˆå±±ä¸œæœ¬åœ°â†’å¤®è§†â†’å…¶ä»–å«è§†â†’å…¶ä»–é¢‘é“ï¼‰
        insert_position = 0
        for category, _ in CHANNEL_PRIORITY:
            for channel in self.priority_channels[category]:
                root.insert(insert_position, channel)
                insert_position += 1
                
        # æ·»åŠ å…¶ä»–å›½å†…é¢‘é“
        for channel in self.other_channels:
            root.insert(insert_position, channel)
            insert_position += 1
            
        # æ·»åŠ æ‰€æœ‰èŠ‚ç›®å•
        for program in self.all_programs:
            root.append(program)
            
        return etree.tostring(root, encoding="utf-8", pretty_print=True).decode("utf-8")

    def save_epg_files(self, xml_content: str):
        """ä¿å­˜EPGæ–‡ä»¶ï¼ˆXML+GZIPï¼‰ï¼Œæ¸…ç†æ—§æ–‡ä»¶"""
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # æ¸…ç†æ—§æ–‡ä»¶ï¼Œé¿å…å ç”¨ç©ºé—´
        for f in os.listdir(OUTPUT_DIR):
            if f.endswith(('.xml', '.gz', '.log')):
                try:
                    os.remove(os.path.join(OUTPUT_DIR, f))
                except Exception as e:
                    logging.warning(f"åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥ {f}: {str(e)}")
        
        # ä¿å­˜XMLæ–‡ä»¶
        xml_path = os.path.join(OUTPUT_DIR, "epg.xml")
        with open(xml_path, "w", encoding="utf-8") as f:
            f.write(xml_content)
        xml_size = os.path.getsize(xml_path)
        
        # ä¿å­˜GZIPå‹ç¼©æ–‡ä»¶ï¼ˆèŠ‚çœç©ºé—´ï¼Œæœºé¡¶ç›’æ”¯æŒè‡ªåŠ¨è§£å‹ï¼‰
        gz_path = os.path.join(OUTPUT_DIR, "epg.gz")
        with gzip.open(gz_path, "wb") as f:
            f.write(xml_content.encode("utf-8"))
        gz_size = os.path.getsize(gz_path)
        
        logging.info(f"EPGæ–‡ä»¶ç”Ÿæˆå®Œæˆ: XML={xml_size}å­—èŠ‚, GZIP={gz_size}å­—èŠ‚")

    def print_statistics(self):
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Šï¼Œæ–¹ä¾¿æ ¸å¯¹"""
        total_channels = len(self.channel_ids)
        total_programs = len(self.all_programs)
        
        logging.info("\n" + "="*60)
        logging.info("ğŸ“Š EPGç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
        logging.info("="*60)
        
        for category, _ in CHANNEL_PRIORITY:
            count = len(self.priority_channels[category])
            logging.info(f"  {category}: {count}ä¸ªé¢‘é“")
            
        other_count = len(self.other_channels)
        logging.info(f"  å…¶ä»–å›½å†…é¢‘é“: {other_count}ä¸ª")
        logging.info(f"  æ€»é¢‘é“æ•°: {total_channels}ä¸ª")
        logging.info(f"  æ€»èŠ‚ç›®æ•°: {total_programs}ä¸ª")
        logging.info(f"  è¿‡æ»¤å›½å¤–é¢‘é“: {self.filtered_foreign_count}ä¸ª")
        logging.info("="*60)

    def run(self):
        """ä¸»è¿è¡Œæ–¹æ³•ï¼Œç»Ÿä¸€è°ƒåº¦æ‰€æœ‰æµç¨‹"""
        start_time = time.time()
        logging.info("=== EPGç”Ÿæˆå¼€å§‹ ===")
        
        try:
            # è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„EPGæº
            sources = self.read_epg_sources()
            logging.info(f"è¯»å–åˆ°{len(sources)}ä¸ªEPGæº")
            
            # å¹¶å‘è·å–å¹¶å¤„ç†æ‰€æœ‰æºæ•°æ®
            if not self.fetch_all_sources(sources):
                logging.error("æ‰€æœ‰EPGæºè·å–å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
                return False
                
            # ç”Ÿæˆæœ€ç»ˆçš„XMLå†…å®¹
            xml_content = self.generate_final_xml()
            
            # ä¿å­˜æ–‡ä»¶ï¼ˆXML+GZIPï¼‰
            self.save_epg_files(xml_content)
            
            # è¾“å‡ºç»Ÿè®¡æŠ¥å‘Š
            self.print_statistics()
            
            total_time = time.time() - start_time
            logging.info(f"=== EPGç”Ÿæˆå®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’ ===")
            return True
            
        except Exception as e:
            logging.error(f"EPGç”Ÿæˆå¤±è´¥: {str(e)}")
            return False

def main():
    """ä¸»å‡½æ•°ï¼Œç¨‹åºå…¥å£"""
    generator = EPGGenerator()
    success = generator.run()
    exit(0 if success else 1)

if __name__ == "__main__":
    main()
