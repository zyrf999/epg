import os
import gzip
import re
import time
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Set, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests
from lxml import etree
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ===================== é…ç½®åŒº =====================
CONFIG_FILE = "config.txt"
OUTPUT_DIR = "output"
LOG_FILE = "epg_merge.log"
MAX_WORKERS = 3  # å¹¶å‘çº¿ç¨‹æ•°ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
TIMEOUT = 30
CORE_RETRY_COUNT = 2

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# ä»…ä¿ç•™å¿…è¦çš„æ‰‹åŠ¨æ˜ å°„ï¼ˆä¸ç¡®å®šçš„å¯ä»¥å…¨éƒ¨åˆ é™¤ï¼Œç•™ç©º{}ï¼‰
COOL9_ID_MAPPING = {
    "89": "å±±ä¸œå«è§†", "221": "å±±ä¸œæ•™è‚²", "381": "å±±ä¸œæ–°é—»", 
    "382": "å±±ä¸œå†œç§‘", "383": "å±±ä¸œé½é²", "384": "å±±ä¸œæ–‡æ—…",
    "1": "CCTV1", "2": "CCTV2", "3": "CCTV3", "4": "CCTV4", 
    "5": "CCTV5", "6": "CCTV6", "7": "CCTV7", "8": "CCTV8",
    "9": "CCTV9", "10": "CCTV10"
}

# å›½å¤–é¢‘é“å…³é”®è¯é»‘åå•ï¼ˆå‘½ä¸­åˆ™è¿‡æ»¤ï¼‰
FOREIGN_KEYWORDS = [
    "BBC", "CNN", "NBC", "FOX", "HBO", "Netflix", "Disney",
    "æ¬§ç¾", "ç¾å›½", "è‹±å›½", "æ³•å›½", "å¾·å›½", "æ—¥æœ¬", "éŸ©å›½",
    "æ³°å›½", "è¶Šå—", "å°å°¼", "é©¬æ¥è¥¿äºš", "æ–°åŠ å¡", "æ¾³æ´²",
    "æ¬§æ´²", "ç¾æ´²", "éæ´²", "ä¿„ç½—æ–¯", "å°åº¦", "å·´è¥¿"
]

# å›½å†…ç‰¹æ®Šé¢‘é“å…³é”®è¯ï¼ˆå…œåº•ï¼Œé˜²æ­¢è¯¯è¿‡æ»¤ï¼‰
DOMESTIC_SPECIAL = ["popc", "çˆ±", "æ·˜", "new", "NEW", "POPC", "è¶…çº§ç”µå½±", "IPTV", "newç³»åˆ—", "NewTV"]
# ==================================================

class EPGGenerator:
    def __init__(self):
        self.session = self._create_session()
        self.channel_ids: Set[str] = set()  # å»é‡é¢‘é“ID
        self.all_channels: List = []        # æ‰€æœ‰ä¿ç•™çš„é¢‘é“
        self.all_programs: List = []        # æ‰€æœ‰ä¿ç•™çš„èŠ‚ç›®å•
        self.name_to_final_id = dict()      # é¢‘é“åç§°â†’æœ€ç»ˆæ•°å­—ID æ˜ å°„
        self.program_channel_map = dict()   # ä¸´æ—¶å­˜å‚¨èŠ‚ç›®å•channelæ˜ å°„

    def _create_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯"""
        session = requests.Session()
        retry_strategy = Retry(
            total=CORE_RETRY_COUNT + 2,
            backoff_factor=1.5,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/xml, */*",
            "Accept-Encoding": "gzip, deflate"
        })
        return session

    def read_epg_sources(self) -> List[str]:
        """è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„EPGæº"""
        if not os.path.exists(CONFIG_FILE):
            logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
            
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                sources = []
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line and not line.startswith("#"):
                        if line.startswith(("http://", "https://")):
                            sources.append(line)
                        else:
                            logging.warning(f"ç¬¬{line_num}è¡Œæ ¼å¼é”™è¯¯ï¼Œå·²è·³è¿‡: {line}")
                
                if len(sources) < 1:
                    logging.error(f"æœªæ‰¾åˆ°æœ‰æ•ˆEPGæºï¼Œç¨‹åºé€€å‡º")
                    raise ValueError("æ— æœ‰æ•ˆEPGæº")
                
                return sources[:8]
        except Exception as e:
            logging.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    def clean_xml_content(self, content: str) -> str:
        """æ¸…ç†XMLå†…å®¹ä¸­çš„æ— æ•ˆå­—ç¬¦"""
        content_clean = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', content)
        content_clean = content_clean.replace('& ', '&amp; ')
        return content_clean

    def fetch_single_source(self, source: str) -> Tuple[bool, str, any]:
        """å¹¶å‘è·å–å•ä¸ªEPGæºæ•°æ®"""
        try:
            start_time = time.time()
            logging.info(f"å¼€å§‹æŠ“å–: {source}")
            
            response = self.session.get(source, timeout=TIMEOUT)
            response.raise_for_status()
            
            if source.endswith('.gz'):
                content = gzip.decompress(response.content).decode('utf-8')
            else:
                content = response.text
                
            content_clean = self.clean_xml_content(content)
            xml_tree = etree.fromstring(content_clean.encode('utf-8'))
            
            cost_time = time.time() - start_time
            logging.info(f"æˆåŠŸæŠ“å–: {source} | è€—æ—¶: {cost_time:.2f}s")
            return True, source, xml_tree
            
        except Exception as e:
            logging.error(f"æŠ“å–å¤±è´¥ {source}: {str(e)}")
            return False, source, None

    def normalize_channel_name(self, name: str) -> str:
        """æ ‡å‡†åŒ–é¢‘é“åç§°ï¼ˆç»Ÿä¸€è¯†åˆ«NEWTVç³»åˆ—ï¼‰"""
        name = re.sub(r'[^\u4e00-\u9fff0-9a-zA-Z]', '', name)
        name = name.replace("new", "NEW").replace("newtv", "NEWTV")
        name = re.sub(r'^IHOT|^IPTV', '', name)
        return name.strip()

    def pre_fetch_program_channels(self, sources: List[str]):
        """é¢„æŠ“å–æ‰€æœ‰èŠ‚ç›®å•çš„channelï¼Œå»ºç«‹åç§°â†’æ•°å­—IDæ˜ å°„"""
        logging.info("å¼€å§‹é¢„æŠ“å–èŠ‚ç›®å•é¢‘é“æ˜ å°„...")
        for source in sources:
            try:
                response = self.session.get(source, timeout=TIMEOUT)
                response.raise_for_status()
                
                if source.endswith('.gz'):
                    content = gzip.decompress(response.content).decode('utf-8')
                else:
                    content = response.text
                    
                content_clean = self.clean_xml_content(content)
                xml_tree = etree.fromstring(content_clean.encode('utf-8'))
                
                # æå–æ‰€æœ‰èŠ‚ç›®å•çš„channelï¼ˆæ•°å­—IDï¼‰å’Œå¯¹åº”é¢‘é“åç§°
                programs = xml_tree.xpath("//programme")
                channels = xml_tree.xpath("//channel")
                
                # å»ºç«‹é¢‘é“IDâ†’åç§°æ˜ å°„
                channel_id_to_name = {}
                for ch in channels:
                    cid = ch.get("id", "").strip()
                    display_names = ch.xpath(".//display-name/text()")
                    ch_name = display_names[0].strip() if display_names else cid
                    channel_id_to_name[cid] = ch_name
                
                # å»ºç«‹åç§°â†’æ•°å­—IDæ˜ å°„
                for program in programs:
                    prog_cid = program.get("channel", "").strip()
                    if prog_cid.isdigit() and prog_cid in channel_id_to_name:
                        ch_name = channel_id_to_name[prog_cid]
                        normalized_name = self.normalize_channel_name(ch_name)
                        if normalized_name and normalized_name not in self.program_channel_map:
                            self.program_channel_map[normalized_name] = prog_cid
                            
            except Exception as e:
                logging.warning(f"é¢„æŠ“å–{source}å¤±è´¥: {str(e)}")
        
        logging.info(f"é¢„æŠ“å–å®Œæˆï¼Œå»ºç«‹{len(self.program_channel_map)}ä¸ªåç§°â†’æ•°å­—IDæ˜ å°„")

    def process_channels(self, xml_tree, source: str) -> int:
        """å¤„ç†é¢‘é“ï¼šè‡ªåŠ¨ç»™NEWTVç³»åˆ—åˆ†é…æ•°å­—ID"""
        channels = xml_tree.xpath("//channel")
        add_count = 0
        
        for channel in channels:
            original_cid = channel.get("id", "").strip()
            if not original_cid:
                continue
            
            # è·å–é¢‘é“åç§°å¹¶æ ‡å‡†åŒ–
            display_names = channel.xpath(".//display-name/text()")
            channel_name = display_names[0].strip() if display_names else original_cid
            normalized_name = self.normalize_channel_name(channel_name)
            if not normalized_name:
                continue
            
            # è¿‡æ»¤å›½å¤–é¢‘é“
            if any(kw in channel_name for kw in FOREIGN_KEYWORDS):
                continue
            if any(kw in channel_name for kw in DOMESTIC_SPECIAL):
                pass
            
            # æ ¸å¿ƒä¿®æ”¹ç‚¹1ï¼šå¯¹æ‰€æœ‰é¢‘é“éƒ½å°è¯•ä»é¢„æŠ“å–æ˜ å°„ä¸­è·å–æ•°å­—ID
            final_cid = original_cid
            
            # é¦–å…ˆå°è¯•ä»é¢„æŠ“å–æ˜ å°„ä¸­æŸ¥æ‰¾
            if normalized_name in self.program_channel_map:
                final_cid = self.program_channel_map[normalized_name]
                logging.debug(f"ä»é¢„æŠ“å–æ˜ å°„ä¸­æ‰¾åˆ°åŒ¹é…: '{normalized_name}' -> {final_cid}")
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå¹¶ä¸”æ˜¯NEWTVç³»åˆ—ï¼Œå†å°è¯•å…¶ä»–æ–¹æ³•
            elif "NEWTV" in normalized_name or "NEW" in normalized_name:
                # è‹¥é¢„æŠ“å–å¤±è´¥ï¼Œå°è¯•ä»å½“å‰æºèŠ‚ç›®å•æå–
                programs = xml_tree.xpath('//programme[contains(@channel, "{}")]'.format(normalized_name[:4]))
                if programs:
                    final_cid = programs[0].get("channel", "").strip()
            
            # å¤„ç†æ‰‹åŠ¨æ˜ å°„å’Œå»é‡
            if normalized_name in self.name_to_final_id:
                final_cid = self.name_to_final_id[normalized_name]
            else:
                if original_cid in COOL9_ID_MAPPING:
                    final_cid = COOL9_ID_MAPPING[original_cid]
                elif channel_name in COOL9_ID_MAPPING:
                    final_cid = COOL9_ID_MAPPING[channel_name]
                
                # æ ¸å¿ƒä¿®æ”¹ç‚¹2ï¼šç¡®ä¿æœ€ç»ˆIDæ˜¯æ•°å­—
                # å¦‚æœä¸æ˜¯æ•°å­—ï¼Œå°è¯•ä»é¢„æŠ“å–æ˜ å°„ä¸­æŸ¥æ‰¾
                if not final_cid.isdigit() and normalized_name in self.program_channel_map:
                    final_cid = self.program_channel_map[normalized_name]
            
            if final_cid in self.channel_ids or not final_cid:
                continue
            
            # æ›´æ–°é¢‘é“IDå¹¶ä¿å­˜æ˜ å°„
            channel.set("id", final_cid)
            self.channel_ids.add(final_cid)
            self.name_to_final_id[normalized_name] = final_cid
            self.all_channels.append(channel)
            add_count += 1
                
        logging.info(f"ä»{source}å¤„ç†åˆ°{add_count}ä¸ªæ–°é¢‘é“")
        return add_count

    def get_channel_name_by_id(self, channel_id: str) -> str:
        """æ ¹æ®é¢‘é“IDè·å–é¢‘é“åç§°"""
        for channel in self.all_channels:
            if channel.get("id", "") == channel_id:
                display_names = channel.xpath(".//display-name/text()")
                if display_names:
                    return display_names[0].strip()
        return ""

    def adjust_program_time(self, program, days=0, hours=0):
        """è°ƒæ•´èŠ‚ç›®æ—¶é—´"""
        for attr in ["start", "stop"]:
            time_str = program.get(attr, "")
            if time_str and ' ' in time_str:
                time_part, tz = time_str.split(' ')
                if len(time_part) >= 14:
                    try:
                        dt = datetime.strptime(time_part[:14], "%Y%m%d%H%M%S")
                        
                        # è®°å½•åŸå§‹æ—¶é—´ï¼ˆç”¨äºæ—¥å¿—ï¼‰
                        original = dt.strftime("%Y-%m-%d %H:%M")
                        
                        dt = dt + timedelta(days=days, hours=hours)
                        new_time = dt.strftime("%Y%m%d%H%M%S") + " " + tz
                        program.set(attr, new_time)
                        
                        # è®°å½•è°ƒæ•´è¯¦æƒ…
                        adjusted = dt.strftime("%Y-%m-%d %H:%M")
                        logging.debug(f"æ—¶é—´è°ƒæ•´: {original} -> {adjusted} ({days:+d}å¤© {hours:+d}å°æ—¶)")
                        
                    except Exception as e:
                        logging.warning(f"æ—¶é—´è°ƒæ•´å¤±è´¥ {time_str}: {e}")

    def process_programs(self, xml_tree):
        """å¤„ç†èŠ‚ç›®å•ï¼šä¿®æ­£æ—¶é—´é—®é¢˜"""
        programs = xml_tree.xpath("//programme")
        
        ai_count = 0
        other_count = 0
        
        for program in programs:
            prog_cid = program.get("channel", "").strip()
            
            if prog_cid.isdigit() and prog_cid in self.channel_ids:
                # è·å–é¢‘é“åç§°
                channel_name = self.get_channel_name_by_id(prog_cid)
                
                if channel_name:
                    # åˆ¤æ–­æ˜¯å¦ä¸ºçˆ±ç³»åˆ—
                    is_ai_series = "çˆ±" in channel_name or "iHOT" in channel_name.upper()
                    
                    if is_ai_series:
                        # çˆ±ç³»åˆ—ï¼šåŠ 24å°æ—¶ï¼ˆå› ä¸ºæ…¢äº†ä¸€å¤©ï¼‰â† å·²ä¿®å¤ï¼
                        self.adjust_program_time(program, hours=+24)
                        ai_count += 1
                        logging.info(f"çˆ±ç³»åˆ— {channel_name} æ—¶é—´è°ƒæ•´ +24å°æ—¶")
                    else:
                        # å…¶ä»–é¢‘é“ï¼šåŠ 8å°æ—¶ï¼ˆUTC -> åŒ—äº¬æ—¶é—´ï¼‰
                        self.adjust_program_time(program, hours=+8)
                        other_count += 1
                
                self.all_programs.append(program)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if ai_count > 0 or other_count > 0:
            logging.info(f"æ—¶é—´è°ƒæ•´ç»Ÿè®¡: çˆ±ç³»åˆ— {ai_count}ä¸ª, å…¶ä»–é¢‘é“ {other_count}ä¸ª")

    def fetch_all_sources(self, sources: List[str]) -> bool:
        """å¹¶å‘è·å–æ‰€æœ‰EPGæºå¹¶å¤„ç†"""
        # ç¬¬ä¸€æ­¥ï¼šé¢„æŠ“å–èŠ‚ç›®å•channelæ˜ å°„
        self.pre_fetch_program_channels(sources)
        
        successful_sources = 0
        with ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(sources))) as executor:
            future_to_source = {
                executor.submit(self.fetch_single_source, source): source 
                for source in sources
            }
            
            for future in as_completed(future_to_source):
                source = future_to_source[future]
                try:
                    success, _, xml_tree = future.result()
                    if success and xml_tree is not None:
                        self.process_channels(xml_tree, source)
                        self.process_programs(xml_tree)
                        successful_sources += 1
                        
                except Exception as e:
                    logging.error(f"å¤„ç†æºæ•°æ®å¤±è´¥ {source}: {str(e)}")
        
        if successful_sources == 0:
            logging.error("æ‰€æœ‰EPGæºå¤„ç†å¤±è´¥")
            return False
        return True

    def generate_final_xml(self) -> str:
        """ç”Ÿæˆæœ€ç»ˆEPG XMLæ–‡ä»¶"""
        xml_declare = f'''<?xml version="1.0" encoding="UTF-8"?>
<tv generator-info-name="domestic-epg-generator" 
    generator-info-url="https://github.com/fxq12345/epg" 
    last-update="{time.strftime("%Y%m%d%H%M%S")}">'''
        
        root = etree.fromstring(f"{xml_declare}</tv>".encode("utf-8"))
        
        for channel in self.all_channels:
            root.append(channel)
            
        for program in self.all_programs:
            root.append(program)
            
        return etree.tostring(root, encoding="utf-8", pretty_print=True).decode("utf-8")

    def save_epg_files(self, xml_content: str):
        """ä¿å­˜EPGæ–‡ä»¶"""
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # æ¸…ç†æ—§æ–‡ä»¶
        for f in os.listdir(OUTPUT_DIR):
            if f.endswith(('.xml', '.gz', '.log')):
                try:
                    os.remove(os.path.join(OUTPUT_DIR, f))
                except Exception as e:
                    logging.warning(f"åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥ {f}: {str(e)}")
        
        # ä¿å­˜XMLå’ŒGZIP
        xml_path = os.path.join(OUTPUT_DIR, "epg.xml")
        with open(xml_path, "w", encoding="utf-8") as f:
            f.write(xml_content)
        xml_size = os.path.getsize(xml_path)
        
        gz_path = os.path.join(OUTPUT_DIR, "epg.gz")
        with gzip.open(gz_path, "wb") as f:
            f.write(xml_content.encode("utf-8"))
        gz_size = os.path.getsize(gz_path)
        
        logging.info(f"EPGæ–‡ä»¶ç”Ÿæˆå®Œæˆ: XML={xml_size}å­—èŠ‚, GZIP={gz_size}å­—èŠ‚")

    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡æŠ¥å‘Š"""
        total_channels = len(self.channel_ids)
        total_programs = len(self.all_programs)
        
        logging.info("\n" + "="*50)
        logging.info("ğŸ“Š EPGç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
        logging.info("="*50)
        logging.info(f"  æœ€ç»ˆä¿ç•™é¢‘é“æ•°: {total_channels}ä¸ª")
        logging.info(f"  æœ€ç»ˆä¿ç•™èŠ‚ç›®å•æ•°: {total_programs}ä¸ª")
        logging.info(f"  è‡ªåŠ¨å…³è”åç§°â†’æ•°å­—IDæ•°: {len(self.name_to_final_id)}ä¸ª")
        logging.info("="*50)

    def run(self):
        """ä¸»è¿è¡Œæ–¹æ³•"""
        start_time = time.time()
        logging.info("=== EPGç”Ÿæˆå¼€å§‹ ===")
        
        # æ·»åŠ å½“å‰æ—¶é—´ä¿¡æ¯
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.info(f"å½“å‰ç³»ç»Ÿæ—¶é—´: {current_time}")
        
        try:
            sources = self.read_epg_sources()
            logging.info(f"è¯»å–åˆ°{len(sources)}ä¸ªæœ‰æ•ˆEPGæº")
            
            if not self.fetch_all_sources(sources):
                return False
                
            xml_content = self.generate_final_xml()
            self.save_epg_files(xml_content)
            self.print_statistics()
            
            total_time = time.time() - start_time
            logging.info(f"=== EPGç”Ÿæˆå®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’ ===")
            return True
            
        except Exception as e:
            logging.error(f"EPGç”Ÿæˆå¤±è´¥: {str(e)}")
            return False

def main():
    """ä¸»å‡½æ•°å…¥å£"""
    generator = EPGGenerator()
    success = generator.run()
    exit(0 if success else 1)

if __name__ == "__main__":
    main()
